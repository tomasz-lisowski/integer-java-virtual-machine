# Fuzzing
## Corpus Preparation
First a corpus of inputs must be generated, these will be the inputs that the fuzzer will use as a
starting point:
1. `mkdir corpus-raw`
2. `cp ./files/**/*.ijvm ./corpus-raw -r`
3. `mkdir corpus-cmin`
4. `afl-cmin -i ./corpus-raw -o ./corpus-cmin -t 500 -m 1000 -- ./afl-ijvm @@`
5. `mkdir corpus-tmin`
5. `for bin in ./corpus-cmin/*; do afl-tmin -i ${bin} -o ./corpus-tmin/${bin} -t 500 -m 1000 --
   ../afl-ijvm @@;done;`

This method generates a minimized corpus which helps the fuzzer (`afl-fuzz`) to run faster. The
configuration is set up such that high memory utilization inputs are possible but the short timeout
ensures the fuzzer will not get hung up on these. This means that the fuzzer can find inputs that
can quickly allocate ~1 GB of RAM but ignore those that can do the same in more time. Note that the
~1 GB limit is arbitrary and has been created to speed up fuzzing. 

## Running the Fuzzer
A single instance of `afl-fuzz` utilizes ~one CPU core, hence setting up multiple instances with
minor additional configuration will be able to speed up the process. (this method is described in
[AFL docs](https://github.com/stribika/afl-fuzz/blob/master/docs/perf_tips.txt)).

1. `mkdir afl_sync_dir`
2. Move the contents of `corpus-tmin` into `afl_input`
3. `./build_afl.sh` to produce an instrumented IJVM binary
4. First run the primary instance with `afl-fuzz -i ./afl-input/ -o ./afl-sync-dir/ -M fuzzer00 -t
   500 -m 1000 -- ./afl-ijvm @@`
5. Lastly, start the secondary instance with `afl-fuzz -i ./afl-input/ -o ./afl-sync-dir/ -S
   fuzzer01 -t 500 -m 1000 -- ./afl-ijvm @@`
6. Wait for a long time... :)

## Results
Initially, the fuzzer was running for 3 days after which all crashing inputs were debugged with GDB
(`gdb -ex run --args ./ijvm ./input.ijvm`) to find the bugs and resolve them. 

Next up, the fuzzer was run three more times and after each test, all the discovered bugs were
fixed. These short runs were configured with lower timeouts and memory limits (200 ms and 50 MB) to
find logic bugs and avoid out of memory errors. Lastly, with the assumption that the program is
bug-free, the fuzzer was run for one last time which lasted 1 day and produced only 3 crashing
inputs at which point it was fair to say that if there were more bugs, AFL would not find them.

Below is a discussion of some bugs that came up and how they were mitigated:

- Error handling was initially done by setting an error flag on the CPU inside the VM and allowing  
  functions to return a default value down to the interpreter which would 'step' and run the
  ```finished``` function and determine that it should stop the emulator. This led to various nested
  errors getting printed while the call stack was slowly clearing up; unfortunately, this nesting
  would lead to various other errors. In short, error handling was a mess. The solution was to have
  a strict ```destroy_ijvm_now``` function which kills the VM instantly after all memory is freed.
  This solution worked surprisingly well and essentially made error handling quite robust. The
  surprise came from the fact that the functions responsible for freeing memory before calling 
```exit``` were aware of all allocated memory leading to no leaks while the expected outcome was
that some memory was not managed correctly and would end up unreachable after ```exit```.
- Out of bounds memory reads/writes mainly involved arrays and these often had simple solutions.
  Most of the time a function would require various checks of variable bounds to ensure any access
  to memory was more tightly controlled. A solution to this problem also led to the creation of a
  "Mapped Array" data type that is hardened based on the crashing inputs from before but which could
  be utilized for managing arrays and network connections making the codebase smaller thus also
  making the attack surface smaller.
- Small logic problems were littered all over the code which meant that there was a good chance that
  many paths would lead to crashes (this is evident from the raw fuzzer output information discussed
  in the next section).
- Another problem was extreme cases like infinite memory allocating loops. There were measures in
  place to mitigate this problem which involved bound checks, but these were often un-tested hence
  could contain logic errors. One crashing input generated by AFL repeatedly creates a 10 element
  array then stores the array references inside a stack accessible array which means that memory
  will never be freed until the VM finally crashes. This test input would later become useful when
  stress testing the VM in search of memory allocation and out of memory errors. Eventually, it was
  a matter of making minor changes to the logic which was already in place, but it took quite some
  time to pinpoint the source of the problem due to varying levels of free memory when testing,
  therefore, allowing the bugs to be reproduced by following several different paths. 

Hardening, in general, has led to a slowdown but the difference is quite insignificant compared to
the robustness that was gained. The performance hit can be quantified by comparing a run of
`mandelbread.ijvm` before hardening which took just under 1 second and after, which grew to around
1.2 seconds. This increase occurred mainly due to a large number of additional conditional
statements that needed to be added to check the state of the VM before proceeding with whatever the
program requested it to do.

Automatic tests provided, give a function coverage of around 64% but this includes all the code for
networking and IJDB that are not tested using these tests. The coverage of functions that are
expected to be tested automatically is around 80%. In terms of line coverage, the drop is
significant (~20%) with the addition of conditionals that aim to harden the code, which is expected.
The coverage, in general, is not very high even if un-tested code is omitted but results from AFL
(which tests a much broader number of paths in the program) are promising which suggests that the VM
is at least moderately robust.

## Raw Output
Take a look at the ```misc/afl_raw_output``` directory for screenshots of the AFL fuzzer interface
at the end of each run. Image ```afl_fuzz_1.png``` shows the first (3 days) run. Image
```afl_fuzz_2.png``` shows the kind of data that was collected from the three short runs. Image
```afl_fuzz_3.png``` shows the 'final' run. There was actually another run that was done right
before finishing the project. The results of this run are shown in image ```afl_fuzz_4.png```.
What's interesting about this run is the "stability" statistic because unlike other runs that all
had 100% this one had ~98%. After some analysis, it appears to be that some erroneous programs
required a set amount of memory before reaching an error in the program's code but depending on the
available RAM, the error in the program could be reached, or if there was too little RAM for the
program to progress until the error, the VM would throw an out of memory error, therefore, making
AFL think that this is signifying unstable behavior. The reason why other runs (likely) did not
suffer from such a problem was because of the high (10 GB) memory limit set for this run and the
arbitrary ~1 GB VM limit lifted. 
